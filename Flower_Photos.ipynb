{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/sailahari"
      ],
      "metadata": {
        "id": "SemfnjdQgv0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NlKGzmxDg5eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lkk688/MultiModalClassifier.git"
      ],
      "metadata": {
        "id": "z5RkKQHCjPfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MultiModalClassifier/"
      ],
      "metadata": {
        "id": "Yy2RIztdg8ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "id": "w1LdwMzbg_gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/sailahari/MultiModalClassifier/"
      ],
      "metadata": {
        "id": "How08Bv0hBWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "id": "iL8_f_WshFns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import TFClassifier\n",
        "import TFClassifier.Datasetutil\n",
        "import TFClassifier.Datasetutil.Visutil"
      ],
      "metadata": {
        "id": "jjQJ7jYB590z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !python DatasetTools/getflowerdataset.py"
      ],
      "metadata": {
        "id": "neCCsr74hOFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/sailahari/MultiModalClassifier/"
      ],
      "metadata": {
        "id": "WKOsGmrFhN4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/.keras/datasets/flower_photos"
      ],
      "metadata": {
        "id": "mHY5Jvfchl3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openvino\n",
        "from openvino.runtime import Core"
      ],
      "metadata": {
        "id": "bQhrjVYmiMku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential"
      ],
      "metadata": {
        "id": "nqv5Sg2thzEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openvino.tools.mo import mo_tf"
      ],
      "metadata": {
        "id": "9cgswrvOxGZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('/root/.keras/datasets/flower_photos')\n"
      ],
      "metadata": {
        "id": "4nXXZRkShy8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "2afdSG48idRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/.keras/datasets/flower_photos"
      ],
      "metadata": {
        "id": "ZmotgJvNjlgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "daisy = list(data_dir.glob('daisy/*'))\n",
        "dandelion = list(data_dir.glob('dandelion/*'))\n",
        "sunflowers = list(data_dir.glob('sunflowers/*'))\n"
      ],
      "metadata": {
        "id": "c1BoCXD3idN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PIL.Image.open(str(roses[3]))"
      ],
      "metadata": {
        "id": "Z_nBo_bYj4bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(tulips[0]))"
      ],
      "metadata": {
        "id": "VmEEOM0EinmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "PIL.Image.open(str(daisy[0]))"
      ],
      "metadata": {
        "id": "sfyM6XUyi3Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(dandelion[0]))"
      ],
      "metadata": {
        "id": "JfIPflYskAF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(sunflowers[5]))"
      ],
      "metadata": {
        "id": "qlv1FAXAkJPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "4MZYsW1DkZ9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a dataset for training and testing\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "zXOrarE37a1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Bd36cSgY736d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "laoBphdnkwAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "vGAxVwd77-vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "TLsYjwJdk3mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Tisb__ook67U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n"
      ],
      "metadata": {
        "id": "YFr43vfglApV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "9HmwGN-LlAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "Lxyw02wJlAjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hn9wucsnlAgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.summary()"
      ],
      "metadata": {
        "id": "PxBlzWJWlPpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "\n",
        "history = model.fit(\n",
        "   train_ds,\n",
        "   validation_data=val_ds,\n",
        "   epochs=epochs\n",
        " )"
      ],
      "metadata": {
        "id": "qNdbt7yQlPli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n"
      ],
      "metadata": {
        "id": "maCmqu2YlPiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5yokyGCwlPe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
        "                                                 input_shape=(img_height,\n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "aDLysYMUlPbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "gt_0sUcllPX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "KECqh5WmlPTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GcMABpFmlPPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "EVKAbPVBmXuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "ATCtZddFmXqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n"
      ],
      "metadata": {
        "id": "KEaoQj0AmXn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nMjeMBdCr0Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = keras.preprocessing.image.load_img(sunflower_path, target_size=(img_height, img_width))\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n"
      ],
      "metadata": {
        "id": "AMclcxnHmXlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img_array)"
      ],
      "metadata": {
        "id": "T5BDkYJbmXh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "score = tf.nn.softmax(predictions[0])\n"
      ],
      "metadata": {
        "id": "DwpgXt04pSkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "_18B_nF4mXet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the trained model - a new folder flower will be created\n",
        "#and the file \"saved_model.pb\" is the pre-trained model\n",
        "model_dir = \"model\"\n",
        "model_fname = f\"{model_dir}/flower\"\n",
        "model.save(model_fname)"
      ],
      "metadata": {
        "id": "zXfDwvbPlPMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The paths of the source and converted models\n",
        "model_name = \"flower\"\n",
        "model_path = Path(model_fname)\n",
        "ir_data_type = \"FP16\"\n",
        "ir_model_name = \"flower_ir\"\n",
        "\n",
        "# Get the path to the Model Optimizer script\n",
        "\n",
        "# Construct the command for Model Optimizer\n",
        "mo_command = f\"\"\"mo\n",
        "                 --saved_model_dir \"{model_fname}\"\n",
        "                 --input_shape \"[1,180,180,3]\"\n",
        "                 --data_type \"{ir_data_type}\"\n",
        "                 --output_dir \"{model_fname}\"\n",
        "                 --model_name \"{ir_model_name}\"\n",
        "                 \"\"\"\n",
        "mo_command = \" \".join(mo_command.split())\n",
        "print(\"Model Optimizer command to convert TensorFlow to OpenVINO:\")\n",
        "print(mo_command)"
      ],
      "metadata": {
        "id": "BUM1YEQotAsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Model Optimizer (overwrites the older model)\n",
        "# print(\"Exporting TensorFlow model to IR... This may take a few minutes.\")\n",
        "mo_result = %sx $mo_command"
      ],
      "metadata": {
        "id": "n2mW0YR9tEui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(mo_result))"
      ],
      "metadata": {
        "id": "yDz7MHAktEqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_image(imagePath, img_height=180):\n",
        "    # Model input format\n",
        "    n, h, w, c = [1, img_height, img_height, 3]\n",
        "    image = Image.open(imagePath)\n",
        "    image = image.resize((h, w), resample=Image.BILINEAR)\n",
        "\n",
        "    # Convert to array and change data layout from HWC to CHW\n",
        "    image = np.array(image)\n",
        "    input_image = image.reshape((n, h, w, c))\n",
        "\n",
        "    return input_image"
      ],
      "metadata": {
        "id": "B67nKCdFuxFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=[\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "model_xml = f\"{model_fname}/flower_ir.xml\"\n"
      ],
      "metadata": {
        "id": "bi6mBCWHuxCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load model\n",
        "ie = Core()\n",
        "model = ie.read_model(model=model_xml)\n",
        "\n",
        "# Neural Compute Stick\n",
        "# compiled_model = ie.compile_model(model=model, device_name=\"MYRIAD\")\n",
        "compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
        "\n",
        "del model\n",
        "\n",
        "input_layer = compiled_model.input(0)\n",
        "output_layer = compiled_model.output(0)"
      ],
      "metadata": {
        "id": "6EK02Cb7uw_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_key = compiled_model.input(0)\n",
        "output_key = compiled_model.output(0)\n",
        "network_input_shape = input_key.shape "
      ],
      "metadata": {
        "id": "4dxqBWDJ8OFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datetime"
      ],
      "metadata": {
        "id": "1V4A3XiyAeZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "WuURogWM50kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wget"
      ],
      "metadata": {
        "id": "bBpQWmOd59ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python==4.5.2.54"
      ],
      "metadata": {
        "id": "J8CP1yHh7gva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on the input image...\n",
        "inp_img_url = \"https://upload.wikimedia.org/wikipedia/commons/4/48/A_Close_Up_Photo_of_a_Dandelion.jpg\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "inp_file_name = f\"A_Close_Up_Photo_of_a_Dandelion.jpg\"\n",
        "file_path = Path(OUTPUT_DIR)/Path(inp_file_name)\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Download the image\n",
        "# download(inp_img_url, inp_file_name, directory=OUTPUT_DIR)\n",
        "#download(inp_img_url, inp_file_name)\n",
        "wget.download(inp_img_url,OUTPUT_DIR+inp_file_name)\n",
        "# Pre-process the image and get it ready for inference.\n",
        "input_image = pre_process_image(OUTPUT_DIR+inp_file_name)\n",
        "\n",
        "print(input_image.shape)\n",
        "print(input_layer.shape)\n",
        "res = compiled_model([input_image])[output_layer]\n",
        "\n",
        "score = tf.nn.softmax(res[0])\n",
        "\n",
        "# Show the results\n",
        "image = Image.open(OUTPUT_DIR+inp_file_name)\n",
        "plt.imshow(image)\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "OqwvBkIguw9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}